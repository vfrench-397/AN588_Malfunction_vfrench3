---
title: "vfrench3_FinalHomeworkCode_04"
author: "Victoria French"
date: "10/23/2021"
output: html_document
---

# Homework 4 

## Z test (Proportion Data) Function

Write a simple R function, Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines:

1. Your function should take the following arguments: p1 and n1 (no default) representing the estimated proportion and sample size (i.e., based on your sample data); p2 and n2 (both defaulting to NULL) that contain a second sample’s proportion and sample size data in the event of a two-sample test; p0 (no default) as the expected value for the population proportion; and alternative (default “two.sided”) and conf.level (default 0.95), to be used in the same way as in the function t.test().
2. When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative=“less” or alternative=“greater”, the same as in the use of x and y in the function t.test().
3. The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.
4. The function should contain a check for the rules of thumb we have talked about (n∗p>5 and n∗(1−p)>5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.
5. The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to “conf.level” around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (“two.sided”, “greater”, “less”), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.

```{r}
z.prop.test <- function(p1, n1, p2=NULL, n2=NULL, p0, alternative = 'two.sided', conf.level = 0.95) {
  #One - Sample
  if (is.null(p2) == TRUE |is.null(n2) == TRUE) { 
    #Check for validity of CLT using rule of thumb 
 np <- n1 * p1 
 thumb <- n1 * (1-p1)
 
   #Calculate the Z statistic 
   Z <- (p1 - p0) / sqrt((p0 * (1-p0))/(n1))
   #Compute the corresponding p-value based on the hypothesis being tested. 
   if (alternative == 'less') {
     p <- pnorm(Z, lower.tail = TRUE)
   } 
   if (alternative == 'greater') {
     p <- pnorm(Z, lower.tail = FALSE)
   }
   if (alternative == 'two.sided') {
    if(Z > 0) {p <- (2 * pnorm(Z, lower.tail = FALSE))}
    if(Z < 0) {p <- (2 * pnorm(Z, lower.tail = TRUE))}
   }
   #Calculate CIs 
   lower <- p1 + qnorm((1 - conf.level)/2) * sqrt(p1 * (1-p1)/(n1))
upper <- p1 + qnorm(1 - (1 - conf.level)/2) * sqrt(p1 * (1-p1)/(n1))
ci <- c(lower, upper)
# Print results
cat('1-sample proportions test', '\n', paste('p-value =',p), '\n', paste('Z statistic =', Z), '\n', 'Confidence Interval =', ci, '\n', paste('based on confidence level', conf.level),'\n')

  if (np <= 5 | thumb <= 5) {  message('Warning: CLT violated. rule of thumb too small to assume normality.')
}
 } 
  #Two - Sample
  else {
    #Check Rule of Thumb 
  np1 <- n1 * p1 
 thumb1 <- n1 * (1-p1)
 np2 <- n2 * p2 
 thumb2 <- n2 * (1-p2)
 
   #Calculate pooled proportion.
   pstar <- ((p1 * n1) + (p2 * n2)) / (n1+n2)
   #Calculate Z statistic
   Z <- (p1 - p2) / sqrt((pstar * (1-pstar)) * ((1/n1)+ (1/n2) )) 
   #Compute corresponding p-value based on hypothesis test being conducted
   if (alternative == 'less') {
     p <- pnorm(Z, lower.tail = TRUE)
   } 
   if (alternative == 'greater') {
     p <- pnorm(Z, lower.tail = FALSE)
   }
   if (alternative == 'two.sided') {
    if(Z > 0) {p <- (2 * pnorm(Z, lower.tail = FALSE))}
    if(Z < 0) {p <- (2 * pnorm(Z, lower.tail = TRUE))}
   }
   #Calculate CIs
   lower <- p1-p2 + qnorm((1 - conf.level)/2) * sqrt(p1 * (1-p1)/(n1) + p2 * (1-p2)/n2)
upper <- p1-p2 + qnorm(1 - (1 - conf.level)/2) * sqrt(p1 * (1-p1)/(n1) + p2 * (1-p2)/n2)
ci <- c(lower, upper)

cat('2-sample proportions test', '\n', paste('p-value =',p), '\n', paste('Z statistic =', Z), '\n', 'Confidence Interval =', ci, '\n', paste('based on confidence level', conf.level), '\n')

if (thumb2 <= 5 | thumb1 <= 5 | np1 <= 5| np2 <= 5) {
  message('Warning: CLT violated. Rule of thumb too small to assume normality.')
}
 } 
}
```

*Looks good to me!*

Test Function to see if every possible if statement runs. 
```{r}
z.prop.test(p1 = 1/4, n1= 29, p0= .2)
z.prop.test(p1 = 1/4, n1= 29, p0= .2, alternative = 'less')
z.prop.test(p1 = 1/4, n1= 29, p0= .2, alternative = 'greater')
```

```{r}
z.prop.test(p1 = .77, n1 = 233, p2 = .88 , n2 = 197, alternative = 'less') 
z.prop.test(p1 = .77, n1 = 233, p2 = .88 , n2 = 197, alternative = 'greater') 
z.prop.test(p1 = .77, n1 = 233, p2 = .88 , n2 = 197) 
```

## Linear Regression Model

The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size):

```{r}
library(curl)
library(ggplot2)
```

```{r}
f <- curl('https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall21/KamilarAndCooperData.csv')
data <- read.csv(f, stringsAsFactors = FALSE, header = TRUE)
head(data)
```

### Standard Model 

1. Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text()).

Compute the regression coefficients manually to compare against model created by lm() function. 
```{r}
y.data <- data[is.na(data$MaxLongevity_m) == FALSE & is.na(data$Brain_Size_Species_Mean) == FALSE, ] #First remove any rows where brain size or longevity possess NAs.
y <- y.data$MaxLongevity_m #create your response variable data
x <- y.data$Brain_Size_Species_Mean #create predictor variable data

x #checking for NAs
y

Beta1 <- cor(x,y) * (sd(y)/sd(x)) #calculate Beta1 (slope)
Beta1
Beta0 <- mean(y) - Beta1 * mean(x) #Calculate Beta0 (intercept)
Beta0
#BOTH OF THESE ESTIMATES ARE THE SAMAE AS CALCULATED BY THE MODEL!! 
```

Your new regression line would then just be
```{r}
# y.hat <- Beta1 * x + Beta0
```

OR you can find the same values by plugging in the data to the lm function built into R. 

```{r}
y <- data$MaxLongevity_m
x <- data$Brain_Size_Species_Mean
m <- lm(y ~ x, data=data)
summary(m)
```

```{r}
#extract the equation from the model object for the plot label.
lm_eqn <- function(m) {
a = format(coef(m)[1], digits = 2)
b = format(abs(coef(m)[2]), digits = 2)

  if (coef(m)[2] >= 0)  {
    eq <- paste('y','=', a, '+', b, 'x')
  } else {
    eq <- paste('y','=', a, '-', b, 'x') 
eq
  }
}
```

```{r}
#Create the ggplot item
g <- ggplot(data = data, aes(x = x, y = y)) + geom_point() + geom_smooth(method = "lm", formula = y ~ x) + geom_text(x = 200, y = 750, label= lm_eqn(m))
g
#Schmitt uses annotate function for text on plot

# OR check out ggpmisc package 
#https://stackoverflow.com/questions/7549694/add-regression-line-equation-and-r2-on-graph
```

*Dont forget to label your axes!* 

2. Identify and interpret the point estimate of the slope (β1).

```{r}
t <- coef(summary(m)) #extract coefficients from the linear model
t <- data.frame(unlist(t)) #coerce coefficients into a data frame format
colnames(t) <- c("Est", "SE", "t", "p") #rename columns for easier interpretation of the output
```

```{r}
beta0 <- t$Est[1] #extract beta0 (Intercept) from t data frame
beta0 
beta1 <- t$Est[2] #Extract beta1 (slope) from t data frame
beta1 
```

Interpretation: 

- if the species' average brain size is zero grams then the expected longevity for that species would be 249 months (which rationally is not a good assumption assuming an animal cannot function without a brain.)
- For every 1 gram of additional brain size, a species is expected to increase their longevity by 1.22 months. 

Also, identify and interpret the outcome of the test associated with the hypotheses H0: β1 = 0; HA: β1 ≠ 0. 


```{r}
#When observing the output of the statistical test you should look at the predictor variable test statistic and p-value instead of the intercept because rejection of the null hypothesis of the intercept just indicates the regression line doesn't cross over the y-axis at zero. 
t$t[2] #extract the predictor variables t statistic
t$p[2] #extract the associated p-value 
```

Interpretation: 

- Null hypothesis indicates the predictor variable has no effect on the response variable. With a significant p-value you can reject the null hypothesis and accept the alternative hypothesis that the predictor variable does significantly affect the response variable. Brain size has a significant effect on a species longevity. 

Also, find a 90 percent CI for the slope (β1) parameter.

```{r}
ci <- confint(m, level = 0.90)  #confint() function inherits lm objects and computes associated confidence intervals.
ci[2,] #extract the CIs around the slope (B1) parameter from object ci
```

Our Beta1 value fits nicely within this interval. 

3. Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.

CIs - addresses our uncertainly in the estimate of the mean

Can use the predict function that will take in a linear model object and calculate specified values. The first argument must always be a model. You can pass a newdata argument that specifies the x values to use as predictor values but it must be in a data frame format and must have the column title match the predictor used in the original call of the model. 

```{r}
cis <- predict.lm(m, newdata = data.frame(Brain_Size_Species_Mean = x), interval = "confidence",level = 0.90) 
cis <- as.data.frame(cis, col.names = c('fit', 'lwr', 'upr'))
is.data.frame(cis)
head(cis)
```

PIs - gives the range of actual values of y we might expect to see at a given value of x

```{r}
pi <- predict(m, newdata = data.frame(Brain_Size_Species_Mean = x), interval = "prediction",level = 0.90)
pi <- as.data.frame(pi, col.names = c('fit', 'lwr', 'upr'))
is.data.frame(pi)
str(pi)
```

Create a new working df for the ggplot object 

```{r}
df <- data.frame(cbind(data$Brain_Size_Species_Mean, 
data$MaxLongevity_m, cis, pi))

colnames(df) <- c('x', 'y', 'CIfit', 'CIlwr', 'CIupr', 'PIfit', 'PIlwr', 'PIupr')
```


Plot 
```{r}
g <- ggplot(data = df, aes(x = x, y = y))
g <- g + geom_point(alpha = 1/2)
g <- g + geom_line(aes(x = x, y = CIfit, color = "CI"))
g <- g + geom_line(aes(x = x, y = CIlwr, color = 'CI'))
g <- g + geom_line(aes(x = x, y = CIupr, color = 'CI'))
g <- g + geom_line(aes(x = x, y = PIlwr, color = 'PI'))
g <- g + geom_line(aes(x = x, y = PIupr, color = 'PI'))
g <- g +  scale_color_manual(name='Interval',breaks=c('CI', 'PI'), values=c('CI'='red', 'PI'='blue'))
g
```

4. Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?

Point Estimate
```{r}
predict(m, newdata = data.frame(x = 800))
```

Essentially you are plugging an x into the fitted model equation to produce a y-hat. 

```{r}
(1.2*800) + 249 #outputs slightly off because this is a rounded estimate of the actual fitted equation. 
```

PIs 
```{r}
predict(m, newdata = data.frame(x = 800), interval = "prediction",level = 0.90)
```

I would not expect this prediction at this value of x to be reliable. The value of x is an extreme extrapolation. It is therefore more difficult to justify that the pattern seen in the observed values would carry over to such an extreme value. You can see this as the CIs widen as x values increase because there is less data contributing to the error minimization/ model fitting. Also, realistically there are limits to both variables in the natural world that the model is not taking into account. 

#### Model Check 

We also ran this analysis without checking if the data met the assumptions of linear modeling (normal distribution of residuals and homogeneity of variance). 

We can look at the distribution of residuals by plotting the model object. 

```{r}
plot(m)
```

We can see the residuals and the square root of the standardized residuals are skewed to the left, the QQ plot that is slightly off from a straight line, and lower x values have more leverage. Overall the data looks deviated from normal.

We can double check for normality using a shapiro wilks test. 

```{r}
s <- shapiro.test(m$residuals)
s
```

This returns a W test statistic and a p-value. A low p value indicates deviation from normality and therefore violation of model assumptions. We can see this data set has an extremely low p-value.

### Log Model

Fortunately, we can transform our data to follow a more normal distribution if it is not following the assumptions of a linear regression model

1. Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text()).

```{r}
x <- log(data$Brain_Size_Species_Mean)
y <- log(data$MaxLongevity_m)
m <- lm(y ~ x, data=data)
summary(m)
```

```{r}
g <- ggplot(data = data, aes(x = x, y = y)) + geom_point() + geom_smooth(method = "lm", formula = y ~ x) + geom_text(x = 1.5, y = 6, label= lm_eqn(m))
g
```


2. Identify and interpret the point estimate of the slope (β1).

```{r}
t <- coef(summary(m))
t <- data.frame(unlist(t))
colnames(t) <- c("Est", "SE", "t", "p")
```

```{r}
beta0 <- t$Est[1]
beta0 #intercept
beta1 <- t$Est[2]
beta1 #slope
```

Interpretation: 

- Since we log transformed both variables we have to interpret the coefficients differently from the first regression. Essentially instead of looking at the coefficients in units we can interpret them as percentages of difference. In this case, For every 1% increase in brain size, species are expected to see a .23% increase in their longevity. 

Also, the outcome of the test associated with the hypotheses H0: β1 = 0; HA: β1 ≠ 0. 

```{r}
t$t[2]
t$p[2]
```

Interpretation: 

- Null hypothesis indicates the predictor variable has no effect on the response variable. With a significant p-value you can say the null hypothesis is rejected and therefore the predictor variable does significantly affect the response variable. With the log transformed data we see an even more significant p-value indicating brain size has a significant effect on a species longevity. 

Find a 90 percent CI for the slope (β1) parameter.

```{r}
ci <- confint(m, level = 0.90)  # using the results of lm()
ci[2,]
```

Our Beta1 value fits nicely within this interval. 

3. Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.

CIs - addresses our uncertainly in the estimate of the mean

```{r}
cis <- predict.lm(m, newdata = data.frame(x = x), interval = "confidence",level = 0.90) 
cis <- as.data.frame(cis, col.names = c('fit', 'lwr', 'upr'))
is.data.frame(cis)
head(cis)
```

PIs - gives the range of actual values of y we might expect to see at a given value of x

```{r}
pi <- predict(m, newdata = data.frame(x = x), interval = "prediction",level = 0.90)
pi <- as.data.frame(pi, col.names = c('fit', 'lwr', 'upr'))
is.data.frame(pi)
str(pi)
```

Create a new working df 

```{r}
df <- data.frame(cbind(x, 
y, cis, pi))

colnames(df) <- c('x', 'y', 'CIfit', 'CIlwr', 'CIupr', 'PIfit', 'PIlwr', 'PIupr')
```


Plot 
```{r}
g <- ggplot(data = df, aes(x = x, y = y))
g <- g + geom_point(alpha = 1/2)
g <- g + geom_line(aes(x = x, y = CIfit, color = "CI"))
g <- g + geom_line(aes(x = x, y = CIlwr, color = 'CI'))
g <- g + geom_line(aes(x = x, y = CIupr, color = 'CI'))
g <- g + geom_line(aes(x = x, y = PIlwr, color = 'PI'))
g <- g + geom_line(aes(x = x, y = PIupr, color = 'PI'))
g <- g +  scale_color_manual(name='Interval',breaks=c('CI', 'PI'), values=c('CI'='red', 'PI'='blue'))
g

#Theme command in ggplot 2 for legends 
#also if the color command is in the aesthetic call the legend should pop up automatically!!!

#OR 

#Isabel Suggestion
lm_eqn <- function(df){
    m <- lm(y ~ x, df);
    eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2, 
         list(a = format(unname(coef(m)[1]), digits = 2),
              b = format(unname(coef(m)[2]), digits = 2),
             r2 = format(summary(m)$r.squared, digits = 3)))
    as.character(as.expression(eq));
}
p1 <- g + geom_text(x = 200, y = 400, label = lm_eqn(df), parse = TRUE)
p1
```

4. Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?

Point Estimate 
```{r}
predict(m, newdata = data.frame(x = log(800)))
```

Essentially you are plugging an x into the fitted model equation to produce a y-hat. 

```{r}
(.23*log(800)) + 4.9 #outputs slightly off because this is a rounded estimate of the actual fitted equation. 
```

PIs 
```{r}
predict(m, newdata = data.frame(x = log(800)), interval = "prediction",level = 0.90)
```

In this model the log transformation reduced the range (and skew) of data and allowed the extreme observations to become more normal, or move closer to the actual mean. This reduced the uncertainty surrounding larger x values that was present in the last model. Again you can see this as the CIs seem more consistent and do not greatly increase. Therefore this estimate produced by the log model would seem to be more accurate than the non-transformed estimate. But applying log transformed data conclusions to the original data is difficult so the estimation might be useless. 

#### Model Checking 

Finally, we can check to see if the log transformed data do a better job at following the model assumptions. 

Again we can plot the model object to check the normality of the residuals. 

```{r}
plot(m)
```

And double check these results with Shapiro-Wilks test 

```{r}
s <- shapiro.test(m$residuals)
s
```

We can see the residuals are more normally distributed and the p-value of the Shapiro-Wilks test has increased.

5. Looking at your two models, which do you think is better? Why?

Looking at the two models the log transformation seemed to create a better fitting model. The data assumed the model assumptions, meaning it was not as skewed to the left as the original data. This resulted in smaller and more consistent CIs, and a higher R squared value indicating a stronger linear relationship between the variables than the original model suggests. 

*great! good job with your interpretations.*

# Challenges

1. Getting the output to print neatly for the z-test function. 
2. Arrangement of p1 and p2 to align with the hypotheses and the upper/lower tail tests. I am still confused about their order in the Z statistic calculation.  
3. Kept getting an error message saying the object (The brain size data column of the data frame) didn't exist? when using the predict function. After reading the Book of R, I found out you have to pass the same name to the predict function that you used for the predictor variable to create the original model. Therefore you can't use brainsize as the name of the column unless that was used as the variable in the original model. 
4. Adding a legend in ggplot manually was difficult to find a solution for on any code sharing website. Most people just do it by aes(col= ). 
5. I thought dealing with the NAs in the data set was going to be a bigger hassle than it actually was. There were points especially while using predict that my data frames didn't have the same amount of observations and I thought the NAs were the issue but in actuality I was just calling the information for the function wrong. 
